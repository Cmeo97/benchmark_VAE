{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pythae.models.normalizing_flows import MADE, MADEConfig\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = MADEConfig(input_dim=(10,), hidden_sizes=[20, 10, 3], output_dim=(10, ))#, context_dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(1, dtype=torch.int32)\n",
      "tensor(1, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "made = MADE(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 10)\n",
    "h = torch.randn(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MADE(\n",
       "  (net): Sequential(\n",
       "    (0): MaskedLinear(in_features=10, out_features=20, bias=True)\n",
       "    (1): MaskedLinear(in_features=20, out_features=10, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaskedLinear(in_features=10, out_features=3, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): MaskedLinear(in_features=3, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "made(x, h).mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(1, dtype=torch.int32)\n",
      "tensor(1, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "masks = made._make_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]]),\n",
       " tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.]]),\n",
       " tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.]]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 1., 0.],\n",
       "         [1., 1., 0.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_order(input_size, input_order=\"left-to-right\"):\n",
    "    \"\"\"Returns a degree vectors for the input.\"\"\"\n",
    "    if input_order == \"left-to-right\":\n",
    "        return np.arange(start=1, stop=input_size + 1)\n",
    "    elif input_order == \"right-to-left\":\n",
    "        return np.arange(start=input_size, stop=0, step=-1)\n",
    "    elif input_order == \"random\":\n",
    "        ret = np.arange(start=1, stop=input_size + 1)\n",
    "        np.random.shuffle(ret)\n",
    "        return ret\n",
    "\n",
    "\n",
    "def create_degrees(\n",
    "    input_size, hidden_units, input_order=\"left-to-right\", hidden_degrees=\"equal\"\n",
    "):\n",
    "    input_order = create_input_order(input_size, input_order)\n",
    "    degrees = [input_order]\n",
    "    for units in hidden_units:\n",
    "        if hidden_degrees == \"random\":\n",
    "            # samples from: [low, high)\n",
    "            degrees.append(\n",
    "                np.random.randint(\n",
    "                    low=min(np.min(degrees[-1]), input_size - 1),\n",
    "                    high=input_size,\n",
    "                    size=units,\n",
    "                )\n",
    "            )\n",
    "        elif hidden_degrees == \"equal\":\n",
    "            min_degree = min(np.min(degrees[-1]), input_size - 1)\n",
    "            degrees.append(\n",
    "                np.maximum(\n",
    "                    min_degree,\n",
    "                    # Evenly divide the range `[1, input_size - 1]` in to `units + 1`\n",
    "                    # segments, and pick the boundaries between the segments as degrees.\n",
    "                    np.ceil(\n",
    "                        np.arange(1, units + 1) * (input_size - 1) / float(units + 1)\n",
    "                    ).astype(np.int32),\n",
    "                )\n",
    "            )\n",
    "    return degrees\n",
    "\n",
    "\n",
    "def create_masks(degrees):\n",
    "    \"\"\"Returns a list of binary mask matrices enforcing autoregressivity.\"\"\"\n",
    "    return [\n",
    "        # Create input->hidden and hidden->hidden masks.\n",
    "        (inp[:, np.newaxis] <= out).astype(np.int)\n",
    "        for inp, out in zip(degrees[:-1], degrees[1:])\n",
    "    ] + [\n",
    "        # Create hidden->output mask.\n",
    "        (degrees[-1][:, np.newaxis]\n",
    "        < degrees[0]).astype(np.int)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = create_degrees(10, [20, 10, 3])\n",
    "msks = create_masks(deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]),\n",
       " array([[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]),\n",
       " array([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1]])]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(1, dtype=torch.int32)\n",
      "tensor(1, dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]]),\n",
       " tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.]]),\n",
       " tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.]]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 1., 0.],\n",
       "         [1., 1., 0.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "made._make_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(deg)):\n",
    "    print(deg[i]- made.m[i-1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(1, dtype=torch.int32)\n",
      "tensor(1, dtype=torch.int32)\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "made_masks = made._make_mask()\n",
    "\n",
    "for i in range(len(deg)):\n",
    "    print(abs(msks[i].T- made_masks[i].numpy()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3, 10)\n",
    "h = torch.randn(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'h'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18124/4069216790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pythae/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/benchmark_VAE/src/pythae/models/normalizing_flows/made/made_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mModelOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAn\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrelevant\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mnet_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pythae/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'h'"
     ]
    }
   ],
   "source": [
    "made(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 8, 5, 9, 2, 4, 3, 7, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1, 10)\n",
    "idx = torch.randperm(len(a))\n",
    "a[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 3, 6, 3, 5, 9, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a = torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.7427)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e51c5ac46389dd7ba2bd8215d251ab84152720d3cad2ff91113d77594821aef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pythae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
